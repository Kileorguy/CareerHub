{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import heapq\n",
    "import pymysql\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import  word_tokenize\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "\n",
    "port = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='../')\n",
    "\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "db_username = os.getenv('DB_USERNAME')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_database = os.getenv('DB_DATABASE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host=db_host, port=int(db_port), user=db_username, passwd=db_password, db=db_database)\n",
    "# cur = conn.cursor()\n",
    "# cur.execute(\"SELECT * FROM job_skills\")\n",
    "# print(cur.description)\n",
    "# for row in cur:\n",
    "#     print(row[2])\n",
    "# cur.close()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_dict = {}\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT c.id, skill_name from companies as c JOIN company_jobs cj ON c.id = cj.company_id JOIN job_skills js ON js.job_id = cj.id')\n",
    "\n",
    "for row in cur:\n",
    "    if skills_dict.get(row[0],'') in ('', None):\n",
    "        skills_dict[row[0]] = ''.join(row[1].lower())\n",
    "    else:\n",
    "        final_string = skills_dict.get(row[0]) + ' ' + row[1].lower()\n",
    "        skills_dict[row[0]] = final_string\n",
    "\n",
    "cur.close()\n",
    "print(skills_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_skills_merged = ''\n",
    "\n",
    "user_id = '95b068aa-4320-38cf-bdfe-ed189b9d72fa'\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT skill_name FROM `user_skills` WHERE user_id = \\''+ user_id+'\\'')\n",
    "for row in cur:\n",
    "    user_skills_merged = user_skills_merged + ' '+  row[0].lower()\n",
    "cur.close()\n",
    "\n",
    "print(user_skills_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(tag):\n",
    "    if tag == 'jj':\n",
    "        return 'a'\n",
    "    elif tag in ['vb','nn','rb']:\n",
    "        return tag[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemma(word_list):\n",
    "    lem = []\n",
    "    tags = pos_tag(word_list)\n",
    "    for word, tag in tags:\n",
    "        label = get_label(tag.lower())\n",
    "        if(label!=None):\n",
    "            lem.append(wnl.lemmatize(word,label))\n",
    "        else:\n",
    "            lem.append(wnl.lemmatize(word))\n",
    "\n",
    "    return lem\n",
    "\n",
    "def preProcess(text):\n",
    "    tokenized = word_tokenize(text)\n",
    "    tokenized = [port.stem(word) for word in tokenized if word.isalpha()]\n",
    "    tokenized = lemma(tokenized)\n",
    "    return tokenized\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=preProcess,stop_words='english', binary=True) \n",
    "sparse_matrix = vectorizer.fit_transform(list(skills_dict.values()))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "   sparse_matrix.todense(),\n",
    "   columns=vectorizer.get_feature_names_out(),\n",
    "   index=skills_dict.keys(),\n",
    ")\n",
    "\n",
    "sparse_matrix_user = vectorizer.transform([user_skills_merged])\n",
    "df_user = pd.DataFrame(\n",
    "    sparse_matrix_user.todense(),\n",
    "    columns=vectorizer.get_feature_names_out(),\n",
    "    index = [user_id]\n",
    ")\n",
    "\n",
    "display(df.head(5))\n",
    "display(df_user.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxHeapObj(object):\n",
    "  def __init__(self, val): \n",
    "     self.val = val\n",
    "  def __lt__(self, other): \n",
    "     col,cos = self.val\n",
    "     col1,cos1 = other.val\n",
    "     return cos > cos1\n",
    "  def __eq__(self, other): \n",
    "     col,cos = self.val\n",
    "     col1,cos1 = other.val\n",
    "     return cos == cos1\n",
    "\n",
    "cosine_result = cosine_similarity(df,df_user)\n",
    "heap_result = []\n",
    "for col,cos in zip(df.index,cosine_result):\n",
    "    data = (col,cos)\n",
    "    heapq.heappush(heap_result, MaxHeapObj(data))\n",
    "\n",
    "\n",
    "result_arr =[]\n",
    "for i in range(5):\n",
    "    res = heapq.heappop(heap_result).val\n",
    "    print(res)\n",
    "    result_arr.append(res[0])\n",
    "print(result_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
